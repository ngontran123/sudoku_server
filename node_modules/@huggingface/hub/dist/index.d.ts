type RepoType = "space" | "dataset" | "model";

interface RepoId {
	name: string;
	type: RepoType;
}

type RepoFullName = string | `spaces/${string}` | `datasets/${string}`;

type RepoDesignation = RepoId | RepoFullName;

/** Actually `hf_${string}`, but for convenience, using the string type */
type AccessToken = string;

interface Credentials {
	accessToken: AccessToken;
}

type SpaceHardwareFlavor =
	| "cpu-basic"
	| "cpu-upgrade"
	| "t4-small"
	| "t4-medium"
	| "a10g-small"
	| "a10g-large"
	| "a100-large";

type SpaceSdk = "streamlit" | "gradio" | "docker" | "static";

type SpaceStage =
	| "NO_APP_FILE"
	| "CONFIG_ERROR"
	| "BUILDING"
	| "BUILD_ERROR"
	| "RUNNING"
	| "RUNNING_BUILDING"
	| "RUNTIME_ERROR"
	| "DELETING"
	| "PAUSED"
	| "SLEEPING";

type AccessTokenRole = "admin" | "write" | "contributor" | "read";

type AuthType = "access_token" | "app_token" | "app_token_as_user";

type Task =
	| "text-classification"
	| "token-classification"
	| "table-question-answering"
	| "question-answering"
	| "zero-shot-classification"
	| "translation"
	| "summarization"
	| "conversational"
	| "feature-extraction"
	| "text-generation"
	| "text2text-generation"
	| "fill-mask"
	| "sentence-similarity"
	| "text-to-speech"
	| "automatic-speech-recognition"
	| "audio-to-audio"
	| "audio-classification"
	| "voice-activity-detection"
	| "depth-estimation"
	| "image-classification"
	| "object-detection"
	| "image-segmentation"
	| "text-to-image"
	| "image-to-text"
	| "image-to-image"
	| "unconditional-image-generation"
	| "video-classification"
	| "reinforcement-learning"
	| "robotics"
	| "tabular-classification"
	| "tabular-regression"
	| "tabular-to-text"
	| "table-to-text"
	| "multiple-choice"
	| "text-retrieval"
	| "time-series-forecasting"
	| "visual-question-answering"
	| "document-question-answering"
	| "zero-shot-image-classification"
	| "graph-ml"
	| "other";

interface SpaceRuntime {
	stage: SpaceStage;
	sdk?: SpaceSdk;
	sdkVersion?: string;
	errorMessage?: string;
	hardware?: {
		current: SpaceHardwareFlavor | null;
		currentPrettyName?: string;
		requested: SpaceHardwareFlavor | null;
		requestedPrettyName?: string;
	};
	/** when calling /spaces, those props are only fetched if ?full=true */
	resources?: SpaceResourceConfig;
	/** in seconds */
	gcTimeout?: number | null;
}

interface SpaceResourceRequirement {
	cpu?: string;
	memory?: string;
	gpu?: string;
	gpuModel?: string;
	ephemeral?: string;
}

interface SpaceResourceConfig {
	requests: SpaceResourceRequirement;
	limits: SpaceResourceRequirement;
	replicas?: number;
	throttled?: boolean;
	is_custom?: boolean;
}

interface CommitDeletedEntry {
    operation: "delete";
    path: string;
}
type ContentSource = Blob | URL;
interface CommitFile {
    operation: "addOrUpdate";
    path: string;
    content: ContentSource;
}
type CommitOperation = CommitDeletedEntry | CommitFile;
interface CommitParams {
    title: string;
    description?: string;
    repo: RepoDesignation;
    operations: CommitOperation[];
    credentials?: Credentials;
    /** @default "main" */
    branch?: string;
    /**
     * Parent commit. Optional
     *
     * - When opening a PR: will use parentCommit as the parent commit
     * - When committing on a branch: Will make sure that there were no intermediate commits
     */
    parentCommit?: string;
    isPullRequest?: boolean;
    hubUrl?: string;
    /**
     * Whether to use web workers to compute SHA256 hashes.
     *
     * We load hash-wasm from a CDN inside the web worker. Not sure how to do otherwise and still have a "clean" bundle.
     */
    useWebWorkers?: boolean | {
        minSize?: number;
        poolSize?: number;
    };
    /**
     * Custom fetch function to use instead of the default one, for example to use a proxy or edit headers.
     */
    fetch?: typeof fetch;
    abortSignal?: AbortSignal;
}
interface CommitOutput {
    pullRequestUrl?: string;
    commit: {
        oid: string;
        url: string;
    };
    hookOutput: string;
}
type CommitProgressEvent = {
    event: "phase";
    phase: "preuploading" | "uploadingLargeFiles" | "committing";
} | {
    event: "fileProgress";
    path: string;
    progress: number;
    state: "hashing" | "uploading";
};
/**
 * Internal function for now, used by commit.
 *
 * Can be exposed later to offer fine-tuned progress info
 */
declare function commitIter(params: CommitParams): AsyncGenerator<CommitProgressEvent, CommitOutput>;
declare function commit(params: CommitParams): Promise<CommitOutput>;

declare function createRepo(params: {
    repo: RepoDesignation;
    credentials: Credentials;
    private?: boolean;
    license?: string;
    /**
     * Only a few lightweight files are supported at repo creation
     */
    files?: Array<{
        content: ArrayBuffer | Blob;
        path: string;
    }>;
    /** @required for when {@link repo.type} === "space" */
    sdk?: SpaceSdk;
    hubUrl?: string;
    /**
     * Custom fetch function to use instead of the default one, for example to use a proxy or edit headers.
     */
    fetch?: typeof fetch;
}): Promise<{
    repoUrl: string;
}>;

declare function deleteFile(params: {
    credentials: Credentials;
    repo: CommitParams["repo"];
    path: string;
    commitTitle?: CommitParams["title"];
    commitDescription?: CommitParams["description"];
    hubUrl?: CommitParams["hubUrl"];
    fetch?: CommitParams["fetch"];
    branch?: CommitParams["branch"];
    isPullRequest?: CommitParams["isPullRequest"];
    parentCommit?: CommitParams["parentCommit"];
}): Promise<CommitOutput>;

declare function deleteFiles(params: {
    credentials: Credentials;
    repo: CommitParams["repo"];
    paths: string[];
    commitTitle?: CommitParams["title"];
    commitDescription?: CommitParams["description"];
    hubUrl?: CommitParams["hubUrl"];
    branch?: CommitParams["branch"];
    isPullRequest?: CommitParams["isPullRequest"];
    parentCommit?: CommitParams["parentCommit"];
    fetch?: CommitParams["fetch"];
}): Promise<CommitOutput>;

declare function deleteRepo(params: {
    repo: RepoDesignation;
    credentials: Credentials;
    hubUrl?: string;
    /**
     * Custom fetch function to use instead of the default one, for example to use a proxy or edit headers.
     */
    fetch?: typeof fetch;
}): Promise<void>;

/**
 * @returns null when the file doesn't exist
 */
declare function downloadFile(params: {
    repo: RepoDesignation;
    path: string;
    /**
     * If true, will download the raw git file.
     *
     * For example, when calling on a file stored with Git LFS, the pointer file will be downloaded instead.
     */
    raw?: boolean;
    revision?: string;
    /**
     * Fetch only a specific part of the file
     */
    range?: [number, number];
    credentials?: Credentials;
    hubUrl?: string;
    /**
     * Custom fetch function to use instead of the default one, for example to use a proxy or edit headers.
     */
    fetch?: typeof fetch;
}): Promise<Response | null>;

interface FileDownloadInfoOutput {
    size: number;
    etag: string;
    /**
     * In case of LFS file, link to download directly from cloud provider
     */
    downloadLink: string | null;
}
/**
 * @returns null when the file doesn't exist
 */
declare function fileDownloadInfo(params: {
    repo: RepoDesignation;
    path: string;
    revision?: string;
    credentials?: Credentials;
    hubUrl?: string;
    /**
     * Custom fetch function to use instead of the default one, for example to use a proxy or edit headers.
     */
    fetch?: typeof fetch;
    /**
     * To get the raw pointer file behind a LFS file
     */
    raw?: boolean;
    /**
     * To avoid the content-disposition header in the `downloadLink` for LFS files
     *
     * So that on browsers you can use the URL in an iframe for example
     */
    noContentDisposition?: boolean;
}): Promise<FileDownloadInfoOutput | null>;

declare function fileExists(params: {
    repo: RepoDesignation;
    path: string;
    revision?: string;
    credentials?: Credentials;
    hubUrl?: string;
    /**
     * Custom fetch function to use instead of the default one, for example to use a proxy or edit headers.
     */
    fetch?: typeof fetch;
}): Promise<boolean>;

interface DatasetEntry {
    id: string;
    name: string;
    private: boolean;
    downloads: number;
    gated: false | "auto" | "manual";
    likes: number;
    updatedAt: Date;
}
declare function listDatasets(params?: {
    search?: {
        owner?: string;
    };
    credentials?: Credentials;
    hubUrl?: string;
    /**
     * Custom fetch function to use instead of the default one, for example to use a proxy or edit headers.
     */
    fetch?: typeof fetch;
}): AsyncGenerator<DatasetEntry>;

interface ListFileEntry {
    type: "file" | "directory" | "unknown";
    size: number;
    path: string;
    oid: string;
    lfs?: {
        oid: string;
        size: number;
        /** Size of the raw pointer file, 100~200 bytes */
        pointerSize: number;
    };
    /**
     * Only fetched if `expand` is set to `true` in the `listFiles` call.
     */
    lastCommit?: {
        date: string;
        id: string;
        title: string;
    };
    /**
     * Only fetched if `expand` is set to `true` in the `listFiles` call.
     */
    security?: unknown;
}
/**
 * List files in a folder. To list ALL files in the directory, call it
 * with {@link params.recursive} set to `true`.
 */
declare function listFiles(params: {
    repo: RepoDesignation;
    /**
     * Do we want to list files in subdirectories?
     */
    recursive?: boolean;
    /**
     * Eg 'data' for listing all files in the 'data' folder. Leave it empty to list all
     * files in the repo.
     */
    path?: string;
    /**
     * Fetch `lastCommit` and `securityStatus` for each file.
     */
    expand?: boolean;
    revision?: string;
    credentials?: Credentials;
    hubUrl?: string;
    /**
     * Custom fetch function to use instead of the default one, for example to use a proxy or edit headers.
     */
    fetch?: typeof fetch;
}): AsyncGenerator<ListFileEntry>;

interface ModelEntry {
    id: string;
    name: string;
    private: boolean;
    gated: false | "auto" | "manual";
    task?: Task;
    likes: number;
    downloads: number;
    updatedAt: Date;
}
declare function listModels(params?: {
    search?: {
        owner?: string;
        task?: Task;
    };
    credentials?: Credentials;
    hubUrl?: string;
    /**
     * Custom fetch function to use instead of the default one, for example to use a proxy or edit headers.
     */
    fetch?: typeof fetch;
}): AsyncGenerator<ModelEntry>;

type Color = "red" | "yellow" | "green" | "blue" | "indigo" | "purple" | "pink" | "gray";

interface ApiSpaceInfo {
	_id: string;
	id: string;
	arxivIds?: string[];
	author: string;
	cardExists?: true;
	cardError?: unknown;
	cardData?: unknown;
	contributors?: Array<{ user: string; _id: string }>;
	disabled: boolean;
	discussionsDisabled: boolean;
	duplicationDisabled: boolean;
	gated: false | "auto" | "manual";
	gitalyUid: string;
	lastAuthor: { email: string; user?: string };
	lastModified: string; // date
	likes: number;
	likesRecent: number;
	private: boolean;
	updatedAt: string; // date
	sha: string;
	subdomain: string;
	title: string;
	emoji: string;
	colorFrom: Color;
	colorTo: Color;
	pinned: boolean;
	siblings: Array<{ rfilename: string }>;
	sdk?: SpaceSdk;
	runtime?: SpaceRuntime;
	models?: string[];
	datasets?: string[];
	originSpace?: { _id: string; authorId: string };
}

type SpaceEntry = {
    id: string;
    name: string;
    sdk?: SpaceSdk;
    likes: number;
    private: boolean;
    updatedAt: Date;
} & Partial<Omit<ApiSpaceInfo, "updatedAt">>;
declare function listSpaces(params?: {
    search?: {
        owner?: string;
    };
    credentials?: Credentials;
    hubUrl?: string;
    /**
     * Custom fetch function to use instead of the default one, for example to use a proxy or edit headers.
     */
    fetch?: typeof fetch;
    /**
     * Additional fields to fetch from huggingface.co.
     */
    additionalFields?: Array<keyof ApiSpaceInfo>;
}): AsyncGenerator<SpaceEntry>;

/**
Matches a JSON object.

This type can be useful to enforce some input to be JSON-compatible or as a super-type to be extended from. Don't use this as a direct return type as the user would have to double-cast it: `jsonObject as unknown as CustomResponse`. Instead, you could extend your CustomResponse type from it to ensure your type only uses JSON-compatible types: `interface CustomResponse extends JsonObject { … }`.

@category JSON
*/
type JsonObject = {[Key in string]: JsonValue} & {[Key in string]?: JsonValue | undefined};

/**
Matches a JSON array.

@category JSON
*/
type JsonArray = JsonValue[] | readonly JsonValue[];

/**
Matches any valid JSON primitive value.

@category JSON
*/
type JsonPrimitive = string | number | boolean | null;

/**
Matches any valid JSON value.

@see `Jsonify` if you need to transform a type to one that is assignable to `JsonValue`.

@category JSON
*/
type JsonValue = JsonPrimitive | JsonObject | JsonArray;

declare global {
	// eslint-disable-next-line @typescript-eslint/consistent-type-definitions -- It has to be an `interface` so that it can be merged.
	interface SymbolConstructor {
		readonly observable: symbol;
	}
}

/**
Returns a boolean for whether the two given types are equal.

@link https://github.com/microsoft/TypeScript/issues/27024#issuecomment-421529650
@link https://stackoverflow.com/questions/68961864/how-does-the-equals-work-in-typescript/68963796#68963796

Use-cases:
- If you want to make a conditional branch based on the result of a comparison of two types.

@example
```
import type {IsEqual} from 'type-fest';

// This type returns a boolean for whether the given array includes the given item.
// `IsEqual` is used to compare the given array at position 0 and the given item and then return true if they are equal.
type Includes<Value extends readonly any[], Item> =
	Value extends readonly [Value[0], ...infer rest]
		? IsEqual<Value[0], Item> extends true
			? true
			: Includes<rest, Item>
		: false;
```

@category Type Guard
@category Utilities
*/
type IsEqual<A, B> =
	(<G>() => G extends A ? 1 : 2) extends
	(<G>() => G extends B ? 1 : 2)
		? true
		: false;

/**
Filter out keys from an object.

Returns `never` if `Exclude` is strictly equal to `Key`.
Returns `never` if `Key` extends `Exclude`.
Returns `Key` otherwise.

@example
```
type Filtered = Filter<'foo', 'foo'>;
//=> never
```

@example
```
type Filtered = Filter<'bar', string>;
//=> never
```

@example
```
type Filtered = Filter<'bar', 'foo'>;
//=> 'bar'
```

@see {Except}
*/
type Filter<KeyType, ExcludeType> = IsEqual<KeyType, ExcludeType> extends true ? never : (KeyType extends ExcludeType ? never : KeyType);

type ExceptOptions = {
	/**
	Disallow assigning non-specified properties.

	Note that any omitted properties in the resulting type will be present in autocomplete as `undefined`.

	@default false
	*/
	requireExactProps?: boolean;
};

/**
Create a type from an object type without certain keys.

We recommend setting the `requireExactProps` option to `true`.

This type is a stricter version of [`Omit`](https://www.typescriptlang.org/docs/handbook/release-notes/typescript-3-5.html#the-omit-helper-type). The `Omit` type does not restrict the omitted keys to be keys present on the given type, while `Except` does. The benefits of a stricter type are avoiding typos and allowing the compiler to pick up on rename refactors automatically.

This type was proposed to the TypeScript team, which declined it, saying they prefer that libraries implement stricter versions of the built-in types ([microsoft/TypeScript#30825](https://github.com/microsoft/TypeScript/issues/30825#issuecomment-523668235)).

@example
```
import type {Except} from 'type-fest';

type Foo = {
	a: number;
	b: string;
};

type FooWithoutA = Except<Foo, 'a'>;
//=> {b: string}

const fooWithoutA: FooWithoutA = {a: 1, b: '2'};
//=> errors: 'a' does not exist in type '{ b: string; }'

type FooWithoutB = Except<Foo, 'b', {requireExactProps: true}>;
//=> {a: number} & Partial<Record<"b", never>>

const fooWithoutB: FooWithoutB = {a: 1, b: '2'};
//=> errors at 'b': Type 'string' is not assignable to type 'undefined'.
```

@category Object
*/
type Except<ObjectType, KeysType extends keyof ObjectType, Options extends ExceptOptions = {requireExactProps: false}> = {
	[KeyType in keyof ObjectType as Filter<KeyType, KeysType>]: ObjectType[KeyType];
} & (Options['requireExactProps'] extends true
	? Partial<Record<KeysType, never>>
	: {});

/**
Useful to flatten the type output to improve type hints shown in editors. And also to transform an interface into a type to aide with assignability.

@example
```
import type {Simplify} from 'type-fest';

type PositionProps = {
	top: number;
	left: number;
};

type SizeProps = {
	width: number;
	height: number;
};

// In your editor, hovering over `Props` will show a flattened object with all the properties.
type Props = Simplify<PositionProps & SizeProps>;
```

Sometimes it is desired to pass a value as a function argument that has a different type. At first inspection it may seem assignable, and then you discover it is not because the `value`'s type definition was defined as an interface. In the following example, `fn` requires an argument of type `Record<string, unknown>`. If the value is defined as a literal, then it is assignable. And if the `value` is defined as type using the `Simplify` utility the value is assignable.  But if the `value` is defined as an interface, it is not assignable because the interface is not sealed and elsewhere a non-string property could be added to the interface.

If the type definition must be an interface (perhaps it was defined in a third-party npm package), then the `value` can be defined as `const value: Simplify<SomeInterface> = ...`. Then `value` will be assignable to the `fn` argument.  Or the `value` can be cast as `Simplify<SomeInterface>` if you can't re-declare the `value`.

@example
```
import type {Simplify} from 'type-fest';

interface SomeInterface {
	foo: number;
	bar?: string;
	baz: number | undefined;
}

type SomeType = {
	foo: number;
	bar?: string;
	baz: number | undefined;
};

const literal = {foo: 123, bar: 'hello', baz: 456};
const someType: SomeType = literal;
const someInterface: SomeInterface = literal;

function fn(object: Record<string, unknown>): void {}

fn(literal); // Good: literal object type is sealed
fn(someType); // Good: type is sealed
fn(someInterface); // Error: Index signature for type 'string' is missing in type 'someInterface'. Because `interface` can be re-opened
fn(someInterface as Simplify<SomeInterface>); // Good: transform an `interface` into a `type`
```

@link https://github.com/microsoft/TypeScript/issues/15300

@category Object
*/
type Simplify<T> = {[KeyType in keyof T]: T[KeyType]} & {};

/**
Create a type that makes the given keys required. The remaining keys are kept as is. The sister of the `SetOptional` type.

Use-case: You want to define a single model where the only thing that changes is whether or not some of the keys are required.

@example
```
import type {SetRequired} from 'type-fest';

type Foo = {
	a?: number;
	b: string;
	c?: boolean;
}

type SomeRequired = SetRequired<Foo, 'b' | 'c'>;
// type SomeRequired = {
// 	a?: number;
// 	b: string; // Was already required and still is.
// 	c: boolean; // Is now required.
// }
```

@category Object
*/
type SetRequired<BaseType, Keys extends keyof BaseType> =
	Simplify<
	// Pick just the keys that are optional from the base type.
	Except<BaseType, Keys> &
	// Pick the keys that should be required from the base type and make them required.
	Required<Pick<BaseType, Keys>>
	>;

type FileName = string;
type TensorName = string;
type Dtype = "F64" | "F32" | "F16" | "BF16" | "I64" | "I32" | "I16" | "I8" | "U8" | "BOOL";
interface TensorInfo {
    dtype: Dtype;
    shape: number[];
    data_offsets: [number, number];
}
type SafetensorsFileHeader = Record<TensorName, TensorInfo> & {
    __metadata__: Record<string, string>;
};
interface SafetensorsIndexJson {
    dtype?: string;
    metadata?: Record<string, string>;
    weight_map: Record<TensorName, FileName>;
}
type SafetensorsShardedHeaders = Record<FileName, SafetensorsFileHeader>;
type SafetensorsParseFromRepo = {
    sharded: false;
    header: SafetensorsFileHeader;
    parameterCount?: Partial<Record<Dtype, number>>;
} | {
    sharded: true;
    index: SafetensorsIndexJson;
    headers: SafetensorsShardedHeaders;
    parameterCount?: Partial<Record<Dtype, number>>;
};
/**
 * Analyze model.safetensors.index.json or model.safetensors from a model hosted
 * on Hugging Face using smart range requests to extract its metadata.
 */
declare function parseSafetensorsMetadata(params: {
    /** Only models are supported */
    repo: RepoDesignation;
    /**
     * Will include SafetensorsParseFromRepo["parameterCount"], an object containing the number of parameters for each DType
     *
     * @default false
     */
    computeParametersCount: true;
    hubUrl?: string;
    credentials?: Credentials;
    revision?: string;
    /**
     * Custom fetch function to use instead of the default one, for example to use a proxy or edit headers.
     */
    fetch?: typeof fetch;
}): Promise<SetRequired<SafetensorsParseFromRepo, "parameterCount">>;
declare function parseSafetensorsMetadata(params: {
    /** Only models are supported */
    repo: RepoDesignation;
    /**
     * Will include SafetensorsParseFromRepo["parameterCount"], an object containing the number of parameters for each DType
     *
     * @default false
     */
    computeParametersCount?: boolean;
    hubUrl?: string;
    credentials?: Credentials;
    revision?: string;
    /**
     * Custom fetch function to use instead of the default one, for example to use a proxy or edit headers.
     */
    fetch?: typeof fetch;
}): Promise<SafetensorsParseFromRepo>;

declare function uploadFile(params: {
    credentials?: Credentials;
    repo: CommitParams["repo"];
    file: URL | File | {
        path: string;
        content: ContentSource;
    };
    commitTitle?: CommitParams["title"];
    commitDescription?: CommitParams["description"];
    hubUrl?: CommitParams["hubUrl"];
    branch?: CommitParams["branch"];
    isPullRequest?: CommitParams["isPullRequest"];
    parentCommit?: CommitParams["parentCommit"];
    fetch?: CommitParams["fetch"];
    useWebWorkers?: CommitParams["useWebWorkers"];
    abortSignal?: CommitParams["abortSignal"];
}): Promise<CommitOutput>;

declare function uploadFiles(params: {
    credentials?: CommitParams["credentials"];
    repo: CommitParams["repo"];
    files: Array<URL | File | {
        path: string;
        content: ContentSource;
    }>;
    commitTitle?: CommitParams["title"];
    commitDescription?: CommitParams["description"];
    hubUrl?: CommitParams["hubUrl"];
    branch?: CommitParams["branch"];
    isPullRequest?: CommitParams["isPullRequest"];
    parentCommit?: CommitParams["parentCommit"];
    fetch?: CommitParams["fetch"];
    useWebWorkers?: CommitParams["useWebWorkers"];
    abortSignal?: CommitParams["abortSignal"];
}): Promise<CommitOutput>;

/**
 * Uploads with progress
 *
 * Needs XMLHttpRequest to be available for progress events for uploads
 * Set useWebWorkers to true in order to have progress events for hashing
 */
declare function uploadFilesWithProgress(params: {
    credentials?: CommitParams["credentials"];
    repo: CommitParams["repo"];
    files: Array<URL | File | {
        path: string;
        content: ContentSource;
    }>;
    commitTitle?: CommitParams["title"];
    commitDescription?: CommitParams["description"];
    hubUrl?: CommitParams["hubUrl"];
    branch?: CommitParams["branch"];
    isPullRequest?: CommitParams["isPullRequest"];
    parentCommit?: CommitParams["parentCommit"];
    abortSignal?: CommitParams["abortSignal"];
    /**
     * Set this to true in order to have progress events for hashing
     */
    useWebWorkers?: CommitParams["useWebWorkers"];
}): AsyncGenerator<CommitProgressEvent, CommitOutput>;

interface WhoAmIUser {
    /** Unique ID persistent across renames */
    id: string;
    type: "user";
    email: string;
    emailVerified: boolean;
    isPro: boolean;
    orgs: WhoAmIOrg[];
    name: string;
    fullname: string;
    canPay: boolean;
    /**
     * @deprecated
     */
    plan?: unknown;
    avatarUrl: string;
    /**
     * Unix timestamp in seconds
     */
    periodEnd: number | null;
}
interface WhoAmIOrg {
    /** Unique ID persistent across renames */
    id: string;
    type: "org";
    name: string;
    fullname: string;
    email: string | null;
    canPay: boolean;
    /**
     * @deprecated
     */
    plan?: unknown;
    avatarUrl: string;
    /**
     * Unix timestamp in seconds
     */
    periodEnd: number | null;
}
interface WhoAmIApp {
    id: string;
    type: "app";
    name: string;
    scope?: {
        entities: string[];
        role: "admin" | "write" | "contributor" | "read";
    };
}
type WhoAmI = WhoAmIApp | WhoAmIOrg | WhoAmIUser;
interface AuthInfo {
    type: AuthType;
    accessToken?: {
        displayName: string;
        expiration?: Date;
        role: AccessTokenRole;
    };
}
declare function whoAmI(params: {
    credentials: Credentials;
    hubUrl?: string;
    /**
     * Custom fetch function to use instead of the default one, for example to use a proxy or edit headers.
     */
    fetch?: typeof fetch;
}): Promise<WhoAmI & {
    auth: AuthInfo;
}>;

/**
 * Error thrown when an API call to the Hugging Face Hub fails.
 */
declare class HubApiError extends Error {
    statusCode: number;
    url: string;
    requestId?: string;
    data?: JsonObject;
    constructor(url: string, statusCode: number, requestId?: string, message?: string);
}
declare class InvalidApiResponseFormatError extends Error {
}

export { AccessToken, AccessTokenRole, AuthInfo, AuthType, CommitDeletedEntry, CommitFile, CommitOperation, CommitOutput, CommitParams, CommitProgressEvent, ContentSource, Credentials, DatasetEntry, Dtype, FileDownloadInfoOutput, HubApiError, InvalidApiResponseFormatError, ListFileEntry, ModelEntry, RepoDesignation, RepoFullName, RepoId, RepoType, SafetensorsFileHeader, SafetensorsIndexJson, SafetensorsParseFromRepo, SafetensorsShardedHeaders, SpaceEntry, SpaceHardwareFlavor, SpaceResourceConfig, SpaceResourceRequirement, SpaceRuntime, SpaceSdk, SpaceStage, Task, TensorInfo, TensorName, WhoAmI, WhoAmIApp, WhoAmIOrg, WhoAmIUser, commit, commitIter, createRepo, deleteFile, deleteFiles, deleteRepo, downloadFile, fileDownloadInfo, fileExists, listDatasets, listFiles, listModels, listSpaces, parseSafetensorsMetadata, uploadFile, uploadFiles, uploadFilesWithProgress, whoAmI };
